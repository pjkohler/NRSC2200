{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import some packages \n",
    "As in often the case, we start our code by importing some Python modules. \n",
    "\n",
    "Remember: **Your code will not work** unless you run the cell in which the modules are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00000-3df10703-604d-4e4d-b7e4-0c48cb7e45da",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6318,
    "execution_start": 1643303697123,
    "source_hash": "b97f439c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import python modules to use for analysis\n",
    "import ebbinghaus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get the data from Open Science Foundation\n",
    "The data files are shared in an public repository at the [Open Science Foundation](https://osf.io/s6mxd/]). \n",
    "\n",
    "The code below calls a function that grabs the data and makes it accessible to the current workbook. \n",
    "\n",
    "If you inspect the function (\"fetch_data\" in ebbinghaus.py) you will notice the structure of the code\n",
    "\n",
    "    !osf --project s6mxd clone\n",
    "    \n",
    "- \"!\" indicates that this we are running something from the command line, outside Python.\n",
    "- \"s6mxd\" is the ID of the project on OSF.\n",
    "- \"clone\" simply means we want to make a local copy of the files from OSF\n",
    "\n",
    "The command will place the files in the local folder \n",
    "\n",
    "    s6mxd/osfstorage/data\n",
    "    \n",
    "which is where we grab the data from in the next step.\n",
    "\n",
    "A limitation that I am still trying to work out is that you cannot specify a subset files that you want to grab, you have to get the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "data already exists, not downloading\n"
     ]
    }
   ],
   "source": [
    "ebbinghaus.fetch_data(\"s6mxd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load and organize the data from each participant\n",
    "\n",
    "The code below loads in the individual data files in csv format that each participant, including you, created when they did the experiment. When running an experiment online, you would normally have some sort of back-end that saves the files automatically somewhere, so you do not have to trust your participant to send you the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00001-1b1b72db-540a-4bc0-9f0b-9cadc7d133af",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2210,
    "execution_start": 1643303894254,
    "source_hash": "ac864561",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding NRSC2200_S2023 : 1456, chance performance\n",
      "Excluding NRSC2200_S2023 : 7823, chance performance\n",
      "Excluding NRSC2200_S2023 : 9092, chance performance\n",
      "Excluding NRSC2200_S2023 : 1493, chance performance\n",
      "Excluding NRSC2200_S2023 : 2543, chance performance\n",
      "Excluding NRSC2200_S2023 : 4733, chance performance\n",
      "Excluding NRSC2200_S2023 : 6160, chance performance\n",
      "Excluding PSYC4260_F2021 : 0972, less than 10 trials with RT < 3 secs\n",
      "Excluding PSYC4260_F2021 : 6555, chance performance\n",
      "Excluding PSYC4260_F2021 : 8491, less than 10 trials with RT < 3 secs\n"
     ]
    }
   ],
   "source": [
    "data_dir = [\"s6mxd/osfstorage/data\"]\n",
    "info_df = ebbinghaus.load_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fit psychometric functions to the data\n",
    "\n",
    "This code uses the function\n",
    "    \n",
    "    ebbinghaus.fit_data()\n",
    "    \n",
    "to fit psychometric functions to the data from each participant. This takes a few minutes. \n",
    "\n",
    "After fitting, the data from all participants are stored in a variable type called a *Pandas dataframe*. This variable type is useful in many ways, including that it makes it easy to save the combined data in a new csv file that can be used statistical analysis or figure making outside of Python. You will not be working with this new csv file in this course, instead you will be grabbing the data directly from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting psychometric functions for \"same\" condition ... finished!\n",
      "Fitting psychometric functions for \"small\" condition ... finished!\n"
     ]
    }
   ],
   "source": [
    "info_df, fit_params = ebbinghaus.fit_data(info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-bd8e3025-eef9-45ac-9a0d-88937cf97e97",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1643303863757,
    "source_hash": "4b09fed"
   },
   "source": [
    "## Assignment 2\n",
    "### Question 1 (4 pts): \n",
    "\n",
    "The code \n",
    "\n",
    "    ebbinghaus.plot_ps(info_df, fit_params, participant_id)\n",
    "    \n",
    "creates two plots, one of the reaction time and one of the responses. The input arguments info_df and fit_params should already be on the workspace if you have run steps 1-5 of the code, and the argument participant_id is a string that indicates the participant ID you want to plot. You can also pass \"means\" to participant_id and the function will plot the average across all participants.\n",
    "\n",
    "Reaction times and responses are plotted seperately for each of the seven physical sizes used for the inner *test disc* (in pixels): 20, 23, 24, 25, 26, 27, 30. The physical size of the inner *reference disc* was always 25 pixels. The same inducers condition is shown in blue, and the small inducers in orange. \n",
    "\n",
    "(a) Please use the function plot_ps to plot the averages across all participants. \n",
    "\n",
    "(b) Then use the function plot_ps to plot your own data - input your own participant ID to the function. If your data was excluded you may plot someone else's ID. Participant \"999\" has very reasonable data. \n",
    "\n",
    "(c) Then draw, by hand, S-shaped *Psychometric functions* through the data, and indicate the approximate *Point of Subjective Equality* (PSE). Do this separately for the same and small inducer conditions, in different colors. Do this for both the average data and your own data.  \n",
    "\n",
    "(d) Based on what you did in 1a-1c, is your effect size, measured using the PSEs, bigger than the average or smaller than the average? Explain why. \n",
    "\n",
    "Your answer should include the code used in a and b (2 lines per question, at most) and screenshots of the *Responses* part of the plot with your hand drawn functions.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work on your answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (4 pts): \n",
    "\n",
    "The code \n",
    "\n",
    "    pse_data = np.array(info_df[[\"pse-same\",\"pse-small\"]])\n",
    "\n",
    "grabs data from the Pandas dataframe to create a 2 x n numpy array that contains the PSEs for the same and small inducers condition, respectively. \n",
    "\n",
    "(a) Please use the *shape* method to get the **number of participants in your dataset** and save that as a integer variable named\n",
    "    \n",
    "    num_subs\n",
    "\n",
    "(b) Please use the methods *mean* and *std* or their corresponding numpy commands to compute the **mean** and **standard deviation**, seperately for the two conditions, and save them as two variables named:\n",
    "\n",
    "    pse_means\n",
    "    pse_stdev\n",
    "\n",
    "Note that both mean and standard deviation can be computed in one line of code.\n",
    "\n",
    "(c) Watch this [video](https://www.youtube.com/watch?v=AQy11Hfp_dU) (also on eClass) to learn how to compute **standard error** using the sample size, and how to convert standard error to the 95% confidence interval. You can use the command *np.sqrt* to take the square root of a number. Save as two variables named:\n",
    "    \n",
    "    pse_stderr # standard error\n",
    "    pse_ci # interval\n",
    "\n",
    "Use the following code to plot your data as a bar plot with error bars:\n",
    "    \n",
    "    plt.bar((0,1), pse_means, yerr=pse_ci, capsize=5)\n",
    "    plt.ylim([15,30])\n",
    "    \n",
    "Try replacing pse_ci with pse_stderr in the above and observe how the error bars change. \n",
    "    \n",
    "(d) The size of the *Ebbinghaus effect* for each participant can be computed as the difference between pse_same and pse_small. Use pse_data to subtract pse_small from pse_same and assign the output to a new variable called:\n",
    "\n",
    "    pse_diff\n",
    "\n",
    "this can be done in one line by selecting the different columns of pse_data. Now use the method *max* or its corresponding numpy command to assign the maximum effect size to a new variable called\n",
    "\n",
    "    pse_max\n",
    "    \n",
    "Bonus: Use the method *argmax* or its corresponding numpy command to get the index of the participant that has the maximum effect size. You can then get the ID of that participant using this command\n",
    "    \n",
    "    print(np.array(info_df[[\"ID\"]])[max_id,0])\n",
    "\n",
    "where max_id is the index. \n",
    "\n",
    "Your answer should include the code used in a-d and a screenshot of the bar plot you created in (c). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work on your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (2 pts):\n",
    "\n",
    "According to the article “The surface area of human V1 predicts the subjective experience of object size”, linked on eClass, what would you expect to be true about primary visual cortex (area V1) of those participants who have the largest Ebbinghaus effects in your experiment?"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cb230051-44ac-4368-ae81-c257a4783978",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
