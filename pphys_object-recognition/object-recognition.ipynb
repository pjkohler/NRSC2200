{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import some packages \n",
    "As in often the case, we start our code by importing some Python modules. \n",
    "\n",
    "Remember: **Your code will not work** unless you run the cell in which the modules are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-3df10703-604d-4e4d-b7e4-0c48cb7e45da",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6318,
    "execution_start": 1643303697123,
    "source_hash": "b97f439c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import python packages to use for analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, spearmanr\n",
    "import ast\n",
    "Z = norm.ppf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get the data from Open Science Foundation\n",
    "The data files are shared in an public repository at the [Open Science Foundation](https://osf.io/bwntz/]). The code below simply grabs the data and makes it accessible to the current workbook. Notice the structure of the code\n",
    "\n",
    "    !osf --project bwntz clone\n",
    "    \n",
    "- \"!\" indicates that this we are running something from the command line, outside Python.\n",
    "- \"bwntz\" is the ID of the project on OSF.\n",
    "- \"clone\" simply means we want to make a local copy of the files from OSF\n",
    "\n",
    "The command will place the files in the local folder \n",
    "\n",
    "    bwntz/osfstorage/data\n",
    "    \n",
    "which is where we grab the data from in the next step.\n",
    "\n",
    "A limitation that I am still trying to work out is that you cannot specify a subset files that you want to grab, you have to get the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!osf --project bwntz clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load and organize the data from each participant\n",
    "\n",
    "The code below loads in the individual data files in csv format that each participant, including you, created when they did the experiment. When running an experiment online, you would normally have some sort of back-end that saves the files automatically somewhere, so you do not have to trust your participant to send you the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-1b1b72db-540a-4bc0-9f0b-9cadc7d133af",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2210,
    "execution_start": 1643303894254,
    "source_hash": "ac864561",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = [\"bwntz/osfstorage/data\"] # list of data folders - compatible with more than one experiment\n",
    "\n",
    "# define empty lists that will hold the number of subjects, rejected subjects and test subjects\n",
    "sub_count = [0]*len(data_dir)    # included datasets\n",
    "reject_count = [0]*len(data_dir) # complete datasets, but rejected due to performance\n",
    "test_count = [0]*len(data_dir)   # incomplete test datasets\n",
    "\n",
    "complete_subs = [] # subjects that produced complete datasets\n",
    "\n",
    "exp_n = 199 # number of experiment trials\n",
    "\n",
    "all_data = []\n",
    "# define object labels here\n",
    "labels = ['bear','elephant','person','car','dog','apple','chair','plane','bird','zebra']\n",
    "\n",
    "for e, cur_dir in enumerate(data_dir):\n",
    "    file_list = glob.glob(cur_dir + \"/**/object_recognition*.csv\")\n",
    "    file_list.sort()\n",
    "    exp_subs = [] # list to hold the subjects in this experiment\n",
    "    for file in file_list:\n",
    "        # load the data\n",
    "        try:\n",
    "            sub_data = pd.read_csv(file)\n",
    "            if \"trial_type\" not in sub_data:\n",
    "                sub_data = pd.read_csv(file, skiprows=1)\n",
    "            # in the past, some trials were duplicated in the data file, the code below takes care of that\n",
    "            sub_data = sub_data[sub_data['trial_index'].apply(lambda x: str(x).isdigit())]\n",
    "            sub_data = sub_data.drop_duplicates()\n",
    "        except:\n",
    "            print(\"Failed to load file {0}\".format(file.split(cur_dir)[1]))\n",
    "        # get id\n",
    "        try:\n",
    "            survey_resp = sub_data[sub_data[\"trial_type\"]==\"survey-html-form\"][\"responses\"].values[0]\n",
    "            survey_resp = survey_resp.replace(':\"}',':\"\"}')\n",
    "            sub_info = ast.literal_eval(survey_resp)\n",
    "        except:\n",
    "            sub_info = {}\n",
    "        # see if id was stored\n",
    "        if 'p_id' in sub_info.keys():  \n",
    "            sub_id = sub_info[\"p_id\"]\n",
    "        else:\n",
    "            sub_id = \"nan\"\n",
    "            \n",
    "        # do quality control on the data\n",
    "        if sub_data.shape[1] < 10:\n",
    "            print(e, sub_id, \"incomplete file, shape:{0}x{1}\".format(sub_data.shape[0],sub_data.shape[1]))\n",
    "            test_count[e] = test_count[e] + 1 # record test subject to the test_count, by adding 1 at the relevant position\n",
    "            continue\n",
    "        \n",
    "        # now skip if this subjects data is already in the set\n",
    "        if sub_id in exp_subs:\n",
    "            print(e, sub_id, \"duplicate participants, skipping the second file\".format(num_trials))\n",
    "            continue\n",
    "        \n",
    "        # now we can start working with the data\n",
    "        images = sub_data[\"images\"]\n",
    "        left_choice = sub_data[\"left_choice\"]\n",
    "        right_choice = sub_data[\"right_choice\"]\n",
    "        rts = sub_data[\"rt\"]\n",
    "        response = sub_data[\"button_pressed\"] # 0 = left; 1 = right;\n",
    "        \n",
    "        valid_loc = [ ~np.isnan(x) for x in images ]\n",
    "        valid_images = [ int(x) for i, x in enumerate(images) if valid_loc[i] ] # image number\n",
    "        valid_left = [ int(x) for i, x in enumerate(left_choice) if valid_loc[i] ] # which object appeared as left choice\n",
    "        valid_right = [ int(x) for i, x in enumerate(right_choice) if valid_loc[i] ]\n",
    "        valid_response = [ int(response[i+1]) for i, x in enumerate(response) if valid_loc[i] ] # which side did the subject choose\n",
    "        choices = [ [l, r] for l, r in zip(valid_left, valid_right) ]\n",
    "        valid_rt = [ float(rts[i+1]) for i, x in enumerate(rts) if valid_loc[i] ] # reaction time\n",
    "        \n",
    "        correct_obj_no = np.tile(range(10),[20,1])\n",
    "        correct_obj_no = correct_obj_no.flatten(\"F\") # corresponding correct object number per image\n",
    "        correct_choice = [ correct_obj_no[x] for x in valid_images ]\n",
    "        \n",
    "        \n",
    "        # final steps of quality control - do we actually have the expected number of trials?\n",
    "        num_trials = sum(valid_loc) # total trials\n",
    "        if num_trials < exp_n:\n",
    "            print(e, sub_id, \"incomplete file, on {0} trials\".format(num_trials))\n",
    "        \n",
    "        # add participant to list of subjects for this experiment\n",
    "        exp_subs.append(sub_id)\n",
    "        \n",
    "        # start populating sub_info dict: \n",
    "        sub_info[\"experiment\"] = e\n",
    "        sub_info[\"ID\"] = sub_id\n",
    "        \n",
    "        # lets fetch all the relevant trial variables for each trial\n",
    "        sub_info[\"im_no\"] = valid_images; # all image numbers\n",
    "        sub_info[\"target\"] = correct_choice; # what was the target object number?            \n",
    "        sub_info[\"distractor\"] = [ int(np.array(i) [i != j ]) for i, j in zip(choices, correct_choice) ] # what was the distractor object number?\n",
    "        sub_info[\"response\"] = [ i [j] for i, j in zip(choices, valid_response) ] # which object with the subject choose?\n",
    "        sub_info[\"correct\"] = [i == j for i, j in zip(sub_info[\"response\"], sub_info[\"target\"])]\n",
    "        sub_info[\"rt\"] = valid_rt\n",
    "        \n",
    "        unique_objects = np.unique(correct_obj_no) # unique object numbers\n",
    "        num_objects = len(unique_objects);      # how many objects are there?\n",
    "        \n",
    "        # generate confusion matrix\n",
    "        sub_conf = np.empty((num_objects, num_objects))\n",
    "        sub_conf[:] = np.nan\n",
    "        conf_labels = []\n",
    "        for i in unique_objects:\n",
    "            for j in unique_objects:\n",
    "                cur_idx = [t == i and d == j for t,d in zip(sub_info[\"target\"], sub_info[\"distractor\"])]\n",
    "                if np.sum(cur_idx) > 0:\n",
    "                    sub_conf[i,j] = 1 - np.nanmean(np.array(sub_info[\"correct\"])[cur_idx])\n",
    "                if file == file_list[-1]:\n",
    "                    # labels will be the same for all subjects, so only create for the last one\n",
    "                    conf_labels.append(labels[i] + \"_vs_\" + labels[j])\n",
    "        sub_info[\"conf\"] = sub_conf\n",
    "        all_data.append(sub_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Average confusion matrices and accuracies over participants\n",
    "You may re-run this code after removing subjects from all_conf and all_corr that more than two standard errors away from the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conf = np.array([x[\"conf\"] for x in all_data ])\n",
    "mean_conf = np.nanmean(all_conf, 0)\n",
    "all_corr = np.array([np.mean(x[\"correct\"]) for x in all_data ])\n",
    "mean_corr = np.nanmean(all_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Plot accuracies for each image pair\n",
    "Now we will plot the accuracies for each image pair. We will use the values from the confusion matrix, but convert them into a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of nans and convert to list\n",
    "conf_list = list(mean_conf.flatten())\n",
    "label_list = conf_labels\n",
    "\n",
    "# combine the two lists and convert confusion to accuracy\n",
    "temp = [(1-t[0],t[1]) for t in zip(conf_list, label_list) if not np.isnan(t[0]) ]\n",
    "\n",
    "# sort by accuracy and pull apart\n",
    "conf_list, label_list = (list(t) for t in zip(*sorted(temp)))\n",
    "\n",
    "# this was a variable I used when bebugging\n",
    "test = [{t:c} for t,c in zip(conf_list, label_list)]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,5))\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "plt.rc('font', **font)\n",
    "plt.plot(conf_list)\n",
    "ax.set_xticks(range(0,len(label_list)+1,10))\n",
    "#ax.set_xticklabels(label_list[0:10:],rotation = 45, ha=\"center\")\n",
    "plt.xlabel(\"image pair\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create a confusion matrix\n",
    "The code below makes a confusion matrix. Each cell reflects the proportion of trials where the non-target image (distractor) was chosen for each image pair. Since the target and distractor were always different, the diagonal is colored white and marked with \"NA\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-e5a56cd0-53af-4308-be9f-7429449b1c29",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 47,
    "execution_start": 1643303734785,
    "source_hash": "946e5b8"
   },
   "outputs": [],
   "source": [
    "## convert the numpy array to a pandas dataframe variable\n",
    "conf_df = pd.DataFrame(mean_conf, columns = labels, index = labels)\n",
    "# reorder the labels to reveal category-specific confusion\n",
    "new_labels = ['bear','bird','dog','elephant','zebra','person','apple','car','chair','plane']\n",
    "# apply the new ordering to the dataframe\n",
    "conf_df = conf_df.reindex(columns=new_labels, index=new_labels)\n",
    "# now make a figure\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,10))\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "plt.rc('font', **font)\n",
    "# first plot a only the nan values, so they can be identified\n",
    "sns.heatmap(\n",
    "    np.where(conf_df.isna(), 0, np.nan),\n",
    "    ax=ax,\n",
    "    cbar=False,\n",
    "    annot=np.full_like(conf_df, \"NA\", dtype=object),\n",
    "    fmt=\"\",\n",
    "    annot_kws={\"size\": 10, \"va\": \"center_baseline\", \"color\": \"black\"},\n",
    "    cmap=ListedColormap(['none']),\n",
    "    linewidth=0)\n",
    "# then overlay the actual values from the non-nan cells\n",
    "sns.heatmap(\n",
    "    conf_df, \n",
    "    ax=ax, \n",
    "    vmin=0, vmax=.4, \n",
    "    cbar=True, cbar_kws={'shrink':.4}, \n",
    "    cmap=sns.color_palette(\"viridis\", 100), \n",
    "    square=True) \n",
    "\n",
    "# labels the axes\n",
    "ax.set_xticklabels(new_labels, rotation = 45, ha=\"center\")\n",
    "plt.xlabel(\"distractor\")\n",
    "plt.ylabel(\"target\")\n",
    "ax.set_yticklabels(new_labels, rotation = 45, va=\"center\")\n",
    "ax.tick_params(length=10, width=2)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cb230051-44ac-4368-ae81-c257a4783978",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
